## Lecture 6. Value Function Approximation
---

## 목 차
[1. Introduction]()  
[2. Incremental Methods]()  
[3. Batch Methods]()  


## 1. Introduction
### Large-scale RL
지금까지 우리는 Table look 기반의 방식을 소개했다.   
현실 문제는 state가 매우 많다.  
- Backgammon 보드게임 : $10^{20}$ states
- Computer 바둑 : $10^{170}$ states
- Helicopter : continuous state space

특히 헬리콥터 사례를 보면 lookup table을 만들수가 없다.

Model-free 문제를 scale up 하는 방법은 없을까?

### Value Function Approximation

- 지금까지 우리는 value function을 look up table로 표현했다.
  - 모든 state s는 V(s) 항목을 가진다.
  - 또는 state-action pair s, a는 Q(s) 항목을 가진다.

- 큰 MDP 문제에서는 
  - state나 action이 매우 많아서 메모리에 저장하지 못할 수도 있다.
  - 각 state의 value를 개별적으로 학습하는 것은 매우 느리다.

- 큰 MDP 문제 해결책
  - **function approximation**으로 value function을 추정한다.
![](20230608082229.png)
  - 확인된 states에서 확인안된 states로 일반화한다. (Generalise from seen states to unseen states)
  - MC, TD learning으로 파라미타 $w$를 학습한다.

### Types of Value Function Approximation

![](20230608082601.png)

Function Approximation 방법은 몇가지가 있다.   
우선 approximator는 파라미터 w로 구성된 black boax이다.  
- 위 첫번째 : s를 입력하면 $\hat{v}(s, w)$ 가 출력됨
- 두번째 : s, a를 입력하면 $\hat{q}(s, a, w)$ 가 출력됨
- 세번째 : s를 입력하면 $\hat{q}(s, a_1, w)$ ... $\hat{q}(s, a_m, w)$가 출력됨 (즉 모든 a에 대한 것이 출력됨)

Function Approximator의 종류는 다양한다.
- Linear combinations of features
- Neural network
- Decision tree
- Nearest neighbour
- Fourier / wavelet bases
- ...

이중에서 우리는 미분 가능한 function approximator만 고려한다.
- Linear combinations of features
- Neural network

또한 non-stationary, non-iid 데이터셋에 적합한 학습 방법도 필요하다.

## 2. Incremental method
### Gradient Descent


![](20230608083528.png)


### SGD를 사용한 Value function approx.

- 목표(objective)  : 추정치 $\hat{v}(s, w)$와 실제 value $v_{\pi}(s)$ 사이의 MSE를 최소화하는 파라미터 벡터 w 찾기
![](20230608084647.png)
- GD로 local minimum을 찾는다.
![](20230608084728.png)

- SGD는 gradient 샘플링해서 구한다.
![](20230608084826.png)

### Feature vectors
state를 feature 벡터로 표현해보자.   
예를 들어 n개의 피처가 있다면,,

![](20230608085036.png)

이러한 표현의 예는 다음과 같다.  
- Distance of robot from landmarks
- Trends in the stock market
- Piece and pawn con gurations in chess

이제 다음부터 차례로 approximator를 하나씩 살펴보자.

### Linear Value Function Approximation

- value function을 피처의 선형 조합으로 표현한 것이다.

![](20230608085407.png)

- Objective는 파라미터 w에 대해서 quadratic이다.

![](20230608085450.png)

- quadratic이기 때문에 SGD는 global optimum에 도달한다.
- 업데이트 방법은 간단하다.

![](20230608085612.png)


### Table Lookup Features


